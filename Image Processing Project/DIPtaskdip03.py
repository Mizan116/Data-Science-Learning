# -*- coding: utf-8 -*-
"""1904116LabTaskDIP03.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C6JgsjDU1RlMhaM3pF-xXnsE4803KVSs
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d harshwalia/birds-vs-drone-dataset

import zipfile
zip_ref = zipfile.ZipFile('/content/birds-vs-drone-dataset.zip', 'r')
zip_ref.extractall('/content')
zip_ref.close()

"""**Importing Necessary Packages**"""

from sklearn.preprocessing import LabelEncoder
from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array
from tensorflow.keras.models import Model
from imutils import paths
import numpy as np
import imutils
import cv2
import os
import pickle as cPickle
from sklearn.svm import SVC
from google.colab.patches import cv2_imshow

"""**Extracting Histogram of Oriented Gradients Feature**"""

import os
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn import svm
from sklearn.metrics import accuracy_score
import cv2

# Paths to dataset
dataset_path = '/content/BirdVsDrone'
categories = ['Birds', 'Drones']

# Data and labels
data = []
labels = []

# Load images and labels
for category in categories:
    folder_path = os.path.join(dataset_path, category)
    for img_name in os.listdir(folder_path):
        img_path = os.path.join(folder_path, img_name)
        try:
            # Read and resize image
            img = cv2.imread(img_path)
            img = cv2.resize(img, (64, 64))  # Resize to 64x64
            data.append(img)
            labels.append(category)
        except Exception as e:
            print(f"Error loading image: {img_path}, {e}")

# Convert to numpy arrays
data = np.array(data)
labels = np.array(labels)

# Encode the labels (from strings to integers)
label_encoder = LabelEncoder()
labels = label_encoder.fit_transform(labels)

# Reshape data to 2D (for scaling and SVM input)
n_samples, height, width, channels = data.shape
data_reshaped = data.reshape(n_samples, -1)  # Reshape to (n_samples, height*width*channels)

data_reshaped.shape

data_reshaped

labels

# Standardize the data
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data_reshaped)

"""**Apply PCA**"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import PCA
from sklearn import svm
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt


# Apply PCA to reduce dimensions while retaining 95% of variance
pca = PCA(n_components=0.95)
data_pca = pca.fit_transform(data_scaled)

# Plotting the first 2 principal components
plt.figure(figsize=(6, 4))
for label in np.unique(labels):
    indices = np.where(labels == label)
    plt.scatter(data_pca[indices, 0], data_pca[indices, 1], label=f'Class {label}', alpha=0.8)
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('2D PCA of Bird vs Drone Dataset')
plt.legend()
plt.show()

pca = PCA()
data_pca = pca.fit_transform(data_scaled)
explained_variance_ratio = pca.explained_variance_ratio_
cumulative_variance_ratio = np.cumsum(explained_variance_ratio)
plt.figure(figsize=(8, 6))
plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, alpha=0.8, align='center',
label='Individual explained variance')
plt.step(range(1, len(cumulative_variance_ratio) + 1), cumulative_variance_ratio, where='mid',
label='Cumulative explained variance')
plt.xlabel('Principal component index')
plt.ylabel('Explained variance ratio')
plt.title('Explained Variance Ratio by Principal Component')
plt.legend(loc='best')
plt.show()
threshold = 0.9
num_components = np.argmax(cumulative_variance_ratio >= threshold) + 1
print(f"Number of components to retain 90% variance: {num_components}")

"""**Split the dataset into Train and Test**"""

X_train, X_test, y_train, y_test = train_test_split(data_pca, labels, test_size=0.20, random_state=2)

"""**Train SVM classifier**"""

svclassifier = SVC(kernel='linear')
svclassifier.fit(X_train, y_train)

"""**Predictions on Test Data**"""

y_pred_svm = svclassifier.predict(X_test)
print(classification_report(y_test, y_pred_svm))

"""**Save the model**"""

f = open("/content/model.cPickle", "wb")
f.write(cPickle.dumps(svclassifier))
f.close()

"""**Load the model**"""

model = cPickle.loads(open('/content/model.cPickle', "rb").read())

"""**Prediction on a Sample Data**"""

test_imagePaths = list(paths.list_images('/content/BirdVsDrone/Drones'))

test_imagePaths

from skimage.feature import hog
from skimage.color import rgb2gray
def resize_image(image, size=(64, 64)):
    """Resize the input image to a consistent size."""
    return cv2.resize(image, size)

def extract_hog_features(image, hog_params):
    """Extract HOG (Histogram of Oriented Gradients) features from the image."""
    # Convert the image to grayscale (HOG expects grayscale input)
    gray_image = rgb2gray(image)

    # Extract HOG features
    features, hog_image = hog(gray_image, **hog_params, visualize=True)
    return features

def predict_single_img(img_path, model, scaler, pca, hog_params):
    # Load and preprocess the image
    singleImage = cv2.imread(img_path)
    singleImage = resize_image(singleImage)  # Ensure the image is resized consistently
    print(f"Resized Image Shape: {singleImage.shape}")

    # Extract HOG features
    hist = extract_hog_features(singleImage, hog_params).reshape(1, -1)
    print(f"HOG Features Shape: {hist.shape}")

    # Display the image
    plt.imshow(cv2.cvtColor(singleImage, cv2.COLOR_BGR2RGB))
    plt.title('Input Image')
    plt.show()

    # Scale and apply PCA to the HOG features
    hist_scaled = scaler.transform(hist)  # Use the fitted scaler
    hist_pca = pca.transform(hist_scaled) # Use the fitted PCA

    # Make a prediction
    prediction = model.predict(hist_pca)
    print("Prediction:", prediction)

hog_params = {
    'orientations': 9,
    'pixels_per_cell': (8, 8),
    'cells_per_block': (2, 2),
    'block_norm': 'L2-Hys'
}

predict_single_img(test_imagePaths[0], svclassifier, scaler, pca, hog_params)

# Assuming 'data' contains the images and you extracted HOG features
print(f"Shape of HOG features during training: {hog_features.shape}")

"""**Apply Neural Network**

**Designing a Neural Network Architecture**
"""

import tensorflow as tf
import matplotlib.pyplot as plt
# Set random seed
tf.random.set_seed(42)

model = tf.keras.Sequential([
    tf.keras.layers.Dense(1024, activation='relu', input_shape=(X_train.shape[1],)),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

model.compile(
    loss=tf.keras.losses.binary_crossentropy,
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),
    metrics=['accuracy']
)
model.summary()

history = model.fit(X_train, y_train, epochs=25, verbose=1)

def plot_history(history):
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Loss over Epochs')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.title('Accuracy over Epochs')
    plt.legend()
    plt.show()
    plot_history(history)

predictions = model.predict(X_test)

threshold = 0.5
predictions = np.where(predictions >= threshold, 1, 0)

predictions

print(classification_report(y_test, predictions))

"""**Prediction on a Sample Data**"""

y_pred_nn = model.predict(X_test)
y_pred_nn = (y_pred_nn >= 0.5).astype(int).flatten()

test_imagePaths = list(paths.list_images('/content/BirdVsDrone/Birds'))

def predict_single_img(img_path, model, scaler, pca, hog_params):
    singleImage = cv2.imread(img_path)
    singleImage = resize_image(singleImage)
    print(singleImage.shape)
    hist = extract_hog_features(singleImage, hog_params).reshape(1, -1)
    print(hist.shape)
    cv2_imshow(singleImage)
    hist_scaled = scaler.transform(hist)
    hist_pca = pca.transform(hist_scaled)

    prediction = model.predict(hist_pca)
    if prediction == 1:
        print("Prediction: Rabbit")
    else:
        print("Prediction: Cat")

predict_single_img(test_imagePaths[10], svclassifier, scaler, pca, hog_params)

from sklearn.metrics import accuracy_score

print("Comparative Analysis:")
print("\nSVM Results:")
print("Accuracy:", accuracy_score(y_test, y_pred_svm))
print("Classification Report:\n", classification_report(y_test, y_pred_svm))

print("\nNeural Network Results:")
print("Accuracy:", accuracy_score(y_test, y_pred_nn))
print("Classification Report:\n", classification_report(y_test, y_pred_nn))